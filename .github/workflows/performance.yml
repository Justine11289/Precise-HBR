name: Performance Tests

on:
  schedule:
    # Run weekly on Sunday at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      users:
        description: 'Number of concurrent users'
        required: false
        default: '10'
      duration:
        description: 'Test duration in seconds'
        required: false
        default: '60'
  push:
    branches: [ main ]
    paths:
      - 'tests/test_performance.py'
      - 'tests/test_load.py'
      - '.github/workflows/performance.yml'

env:
  PYTHON_VERSION: '3.11'

jobs:
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark locust
        
    - name: Create test directories
      run: mkdir -p instance/flask_session
        
    - name: Run performance tests
      run: |
        pytest tests/test_performance.py \
          -v --tb=short \
          --benchmark-json=benchmark-results.json \
          --benchmark-autosave || true
      env:
        FLASK_SECRET_KEY: test-secret-key-for-ci-only-not-for-production
        SMART_CLIENT_ID: test-client-id
        SMART_REDIRECT_URI: http://localhost:8080/callback
        TESTING: "true"
      continue-on-error: true
        
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: |
          benchmark-results.json
          .benchmarks/

  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install locust
        
    - name: Create test directories
      run: mkdir -p instance/flask_session
        
    - name: Start application in background
      run: |
        python -c "from APP import app; app.run(host='0.0.0.0', port=8080, threaded=True)" &
        sleep 10
      env:
        FLASK_SECRET_KEY: test-secret-key-for-ci-only-not-for-production
        SMART_CLIENT_ID: test-client-id
        SMART_REDIRECT_URI: http://localhost:8080/callback
        TESTING: "true"
      continue-on-error: true
        
    - name: Run Locust load tests
      run: |
        if [ -f "tests/locustfile.py" ]; then
          locust -f tests/locustfile.py \
            --headless \
            --users ${{ github.event.inputs.users || '10' }} \
            --spawn-rate 2 \
            --run-time ${{ github.event.inputs.duration || '60' }}s \
            --host http://localhost:8080 \
            --html locust-report.html \
            --csv locust-results || true
        else
          echo "No locustfile.py found, skipping load tests"
        fi
      continue-on-error: true
        
    - name: Upload load test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: load-test-results
        path: |
          locust-report.html
          locust-results*.csv

  performance-summary:
    name: Performance Summary
    runs-on: ubuntu-latest
    needs: [performance-tests, load-tests]
    if: always()
    
    steps:
    - name: Generate summary
      run: |
        echo "## âš¡ Performance Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Performance Tests | ${{ needs.performance-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Load Tests | ${{ needs.load-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "ðŸ“¥ Download detailed reports from the artifacts section." >> $GITHUB_STEP_SUMMARY

